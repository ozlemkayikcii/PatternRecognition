{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0smZUaofY6y1",
        "outputId": "8e8c459c-9015-4349-bf21-abc4048483f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: ['free', 'discount']\n",
            "TF*IDF Matrix (Train):\n",
            " [[0.9486833  0.31622777]\n",
            " [0.9486833  0.31622777]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]]\n",
            "TF*IDF Matrix (Test):\n",
            " [[0. 0.]\n",
            " [1. 0.]]\n",
            "[('dog cat mouse cat', '???'), ('free free smile', '???')]\n",
            "Predicted Classes: ['N' 'S']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "# Mount Google Drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# Training data\n",
        "train_docs = [\n",
        "    (\"free free free buy discount combo pleasure\", \"S\"),\n",
        "    (\"free free free discount pleasure smile smile smile\", \"S\"),\n",
        "    (\"cat mouse\", \"N\"),\n",
        "    (\"cat cat dog dog dog dog\", \"N\"),\n",
        "    (\"mouse\", \"N\")\n",
        "]\n",
        "\n",
        "# Test data\n",
        "test_docs = [\n",
        "    (\"dog cat mouse cat\", \"???\"),\n",
        "    (\"Free free smile\", \"???\")\n",
        "]\n",
        "\n",
        "# Preprocessing to lowercase\n",
        "train_docs = [(doc.lower(), label) for doc, label in train_docs]\n",
        "test_docs = [(doc.lower(), label) for doc, label in test_docs]\n",
        "\n",
        "def calculate_mi(word, docs):\n",
        "    N = len(docs)\n",
        "    word_counts = Counter(word in doc.split() for doc, _ in docs)\n",
        "    class_counts = Counter(label for _, label in docs)\n",
        "\n",
        "    P_W = word_counts[True] / N\n",
        "    P_not_W = word_counts[False] / N\n",
        "\n",
        "    mi = 0\n",
        "    for c in class_counts:\n",
        "        P_C = class_counts[c] / N\n",
        "        P_W_C = sum(word in doc.split() and label == c for doc, label in docs) / N\n",
        "        P_not_W_C = sum(word not in doc.split() and label == c for doc, label in docs) / N\n",
        "\n",
        "        if P_W_C > 0:\n",
        "            mi += P_W_C * math.log(P_W_C / (P_W * P_C), 2)\n",
        "        if P_not_W_C > 0:\n",
        "            mi += P_not_W_C * math.log(P_not_W_C / (P_not_W * P_C), 2)\n",
        "\n",
        "    #print(word_counts )\n",
        "    #print(class_counts)\n",
        "    #print(mi)\n",
        "    return mi\n",
        "\n",
        "# Calculate MI for each word in the training data\n",
        "all_words = set(word for doc, _ in train_docs for word in doc.split())\n",
        "mi_scores = {word: calculate_mi(word, train_docs) for word in all_words}\n",
        "\n",
        "#print(all_words)\n",
        "#print(mi_scores)\n",
        "\n",
        "# Sort and select top 2 words\n",
        "selected_features = sorted(mi_scores, key=mi_scores.get, reverse=True)[:2]\n",
        "print(\"Selected Features:\", selected_features)\n",
        "\n",
        "def compute_tfidf(docs, selected_features):\n",
        "    tfidf_vectorizer = TfidfVectorizer(vocabulary=selected_features)\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform([doc for doc, _ in docs])\n",
        "    return tfidf_matrix.toarray()\n",
        "\n",
        "train_tfidf = compute_tfidf(train_docs, selected_features)\n",
        "print(\"TF*IDF Matrix (Train):\\n\", train_tfidf)\n",
        "\n",
        "# Form the representation matrix for training documents\n",
        "train_labels = [label for _, label in train_docs]\n",
        "\n",
        "# Form the TF*IDF matrix for test documents\n",
        "test_tfidf = compute_tfidf(test_docs, selected_features)\n",
        "print(\"TF*IDF Matrix (Test):\\n\", test_tfidf)\n",
        "\n",
        "# Initialize and train KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(train_tfidf, train_labels)\n",
        "\n",
        "print(test_docs)\n",
        "# Predict the class labels for the test documents\n",
        "test_predictions = knn.predict(test_tfidf)\n",
        "print(\"Predicted Classes:\", test_predictions)\n"
      ]
    }
  ]
}